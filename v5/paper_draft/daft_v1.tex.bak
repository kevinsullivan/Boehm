\documentclass{article} % For LaTeX2e
\usepackage{mltemplate,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}

\title{An Artificial Science for System Value Engineering and Assurance}


\author{
Authors \\
Department of Computer Science\\
University of Virginia\\
Charlottesville, VA 22903 \\
\texttt{xxxx@virginia.edu}
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
abstract goes here

\end{abstract}

\section{Introduction}
\subsection{Problem}
\emph{The system shall be adaptable enough to meet new requirements. It shall be resilient enough to continue operating
acceptably under unexpected conditions. It shall be easy to use. It shall be scalable.}

These and other similarly vague statements about non-functional systems properties (ilities) plague systems engineering
today. These statements reflect deeply important concerns, but in ways that are easily misunderstood, not
subject to reliable validation, and that cannot support rigorous reasoning, design, and verification. Yet engineering
critical non-functional properties is among the most demanding systems engineering challenges.

The underlying problems can be summarized as follows.
\begin{enumerate}
  \item 
  There are no shared foundational scientific and engineering knowledge, and corresponding precise
languages, needed to manage the broad range of non-functional system properties and tradeoffs for complex systems.
These properties include changeability, affordability, dependability, usability, resilience, and many more. Gaps in
precise, shared understanding of ilities and how they interact in specific environments make it hard to communicate
unambiguously about them.
  \item 
  There are no validated, precise, reusable framework/template for multi-quality specification.
  \item 
  There are no usable science for reasoning about how broad range of strategies impact on and induce tradeoffs among broad range of system qualities.
  \item 
  There are no unified approach to system specification/prescription, claims/description, evidence, and assurance.

\end{enumerate}
The results of these problems are seen in costly project and operational failures, major down-side surprises
late in development, and unacceptable risks, costs, and diffculties in developing and certifying critical systems.
\subsection{Purpose of Study}
We propose a rigorous, unified, scientific approach to specification, hypothesis, experiment, evidence, and assurance for system qualities and value for cyber-physical-human (CPH) systems.We will promulgate advances of our approach in the form of understandable and usable software tools to enable community evaluation and eventual practical exploitation and evolution of the science in real systems engineering projects. We will also try to  clarify nature of system qualities and how they contribute to overall system value
\subsection{Significant of Research}

1. Coq is expressive enough to embed a vast range of logics and mathematics, including continuous mathematics, making it a candidate framework for specifying, describing, deriving predictions about, and otherwise reasoning about complex systems, including cyber-physical and perhaps cyber-physical-human systems.

2. grounding and unifying specification and assurance in the scientific method produces conceptual clarity and justifies the use of deductive logic in this context, strengthening Rushby's separation of logical and epistemic reasoning


\section{Literature Review}

Approaches have been proposed to understanding the ilities. Many of them try to focus on the individual ility, and bring a recogonized understanding of it among the community. For example, Laprie et. al  try to summarize the fundamental concepts of dependability, and give definations of it \cite{Laprie:dependability}.  Ross et. al have proposed a semantic approach for specifying change-related ility terms, and define a context free language for changeability requirements statements. safety [John Knight], changeability [Adam Ross), security [].... However, it is far from enough for designing a satisfactory system to just successfully achieve the requirement of one ility but sacrifice the others, because there are normally more than one success-critical stakeholders of each system, and they usually have different ility values, besides, some ileitis conflict with each other, for example, some stakeholders (e.g., end-users) may value the usability most, while some others (e.g., investors) may consider more about the affordability. Therefore, a successful system should achieve a satisfactory balance of ility values for the system's success-critical stakeholders. In other words, when designing a system, we need to consider about all the ilities that the stakeholders value, and reason about tradeoffs between these ilities. Unfortunately, current system acquisition and evolution guidance descriptions have numerous deficiencies and inconsistencies in their coverage of ilities considerations. This situation is becoming more serious as systems and their stakeholders become increasingly complex, dynamic, and diverse \cite{Boehm:ontology}.


\section{Proposed Method}

\subsection{Technical Approach}
We use methods of the sciences of the artificial as an architecture for a unified approach to requirements/specification, system development, claims/hypotheses, experiments and evidence, and assurance, where assurance cases combine mathematically formal system descriptions and theories (including Boehm's taxonomy, for example) with the use of generative skepticism inductive reasoning about evidence.
\subsection{What's new}
The novel elements of our approach are as follows.

1. a scientific methods perspective on assurance.

2. an approach unifying scientific theory, skepticism, deductive inference, experiment, evidence, and reasoned judgment about validity.

3. full use of a maximally expressive formal logic notation in assurance cases, consistent with but significantly extending Rushby's use of deductive logic limited to Horn clauses in assurance cases.

4. a formal approach unifying property definition, system prescription (requirements)  and system description (claims) following Jackson's ontology, and assurance (arguments).

5. development of a reusable theory of multi-quality system value.

6. instantiation of one lower-level theory for change-related ilities.

7. unification of system qualities under a top-most quality of system value (Boehm work).

8. demonstration of formalization of a reusable template for high-level value specification and assurance cases, leveraging Coq's typeclasses and dependent typing constructs.

9. demonstration of possibility for expanding one of the many qualities in the top level to a next level of granularity, specifically for change-related qualities (CSER paper on our formalization of the Ross model).

\subsection{Why it works}
\subsection{Technical Hypotheses}

\section{Technical Evaluation Approach}

\section{Possible Problems}
 
\begin{enumerate}
\item 
The leap from uncertain evidence to logical axioms involves a kind of round-off error, and these errors will then accumulate up the inference tree, yielding levels of doubt at the root that can be unacceptable even if each individual axiom seems to be strongly, even if not absolutely, justified. For example, 700 claims, each supported by evidence at the level P=.999 when conjoined will nevertheless produce P < 0.5 at the root of the tree. A question: can one reason effectively about the nature and magnitude of such error? If doubt is quantified probabilistically and inference trees use only ands and ors then yes, methods of fault tree analysis, can be used. But we often lack probabilities for epistemic doubts. We need "pluggable" methods for propagating doubts up trees.
\item 
Constructive logic and proofs are not understandable and so do not satisfy the human communication requirements for an assurance case
\end{enumerate}


\section{Significant of Research}

\section{Project Plan}
\section{Conclusion}



\small{
\begin{thebibliography}{}

\bibitem{Rushby:safety}
Rushby, J.: Formalism in safety cases. In Dale, C., Anderson, T., eds.: Making Systems Safer: Proceedings of the Eighteenth Safety-Critical Systems Symposium, Bristol, UK, Springer (2010) 3-17 1, 3

\bibitem{Laprie:dependability}
A. Avizienis, J.-C. Laprie and B. Randell: Fundamental Concepts of Dependability. Research Report No 1145, LAAS-CNRS, April 2001

\bibitem{Knight:safety}
Patrick Graydon, John Knight, and Mitchell Green, International System Safety Conference, Minneapolis, MN (September 2010).



\bibitem{Boehm:ontology}
B. Boehm, N. Kukreja: An Initial of an Ontology for System ilities. To be presented in 25th Annual INCOSE International Symposium, July 2015

\end{thebibliography}
}
\end{document}
